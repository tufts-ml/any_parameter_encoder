# Goals

Sanity check the ELBO computation of the current APE code.

Compare the following:

* baseline of a general unigram model
* manual calculation of the ELBO
* calculation of the ELBO with SVI

# Results so far



# Data

1000 documents from a "toy bars" setting.

True topics are generated by:

* beta_KV : 10 topics each with a uniform distribution over one horiz/vertical bar
* theta_KV : drawn from Dir(5 * beta_KV)


# Baseline Unigram model

$$
p( x_n | p) = \text{Multinomial}( T_n, p_1, \ldots p_V), \quad p \in \Delta^V
$$

we fit $p$ via maximum likelihood on the training set.

# Target model: Logistic-Normal Topic model

## Generative Model

$$
p(h) &= \mathcal{N}( \mu_0, \Sigma_0), \quad h \in \mathbb{R}^K
\\
p(x_n | h_n) &= \text{Multinomial}( T_n, \sum_k \pi_k(h) \theta ), \quad x_n \in \mathbb{Z}_+^V
$$

## Prerequisites

Install ape conda environment

```
conda env create -f ape-linux64.yml
```



